---
title: "Appendix S2. Model definitions, model fitting, and model evaluation."
subtitle: Supporting information for Scheuerell et al.
output:
  pdf_document:
    highlight: haddock
    toc: yes
    number_sections: true
    toc_depth: '3'
fontsize: 11pt
geometry: margin=1in
---

```{r set_options, echo = FALSE, message = FALSE}
options(width = 100)
knitr::opts_chunk$set(message = FALSE)
set.seed(123)
if(file.exists("cnt_time.txt")) {
  file.remove("cnt_time.txt")
}
mod_names <- data.frame(mod = rep(c("Ricker", "Beverton-Holt"), 2),
                        cov = rep(c("without", "with"), 2))
```

\vspace{0.2in}

This is version `r paste0('0.',format(Sys.time(), '%y.%m.%d'))`.

# Background

This appendix describes how we fit the models and evaluated their relative performances. It demonstrates how to load the fish data and environmenal covariates, specify the different models in the __JAGS__ software, and fit each one. 

All analyses require the [R software](https://cran.r-project.org/) (v3.4.3 or later) for data retrieval, data processing, and summarizing model results, and the [JAGS software](http://mcmc-jags.sourceforge.net/) (v4.2.0) for Markov chain Monte Carlo (MCMC) simulation. Please note that some of the __R__ code below may not work with older versions of __JAGS__ due to some changes in the ways that arrays are handled.

We also need a few packages that are not included with the base installation of __R__, so we begin by installing them (if necessary) and then loading them.

```{r load_pkgs, message = FALSE, warning = FALSE}
if(!require("here")) {
  install.packages("here")
  library("here")
}
if(!require("readr")) {
  install.packages("readr")
  library("readr")
}
if(!require("R2jags")) {
  install.packages("R2jags")
  library("R2jags")
}
# if(!require("rjags")) {
#   install.packages("rjags")
#   library("rjags")
# }
# if(!require("loo")) {
#   install.packages("loo")
#   library("loo")
# }
## set directory locations
datadir <- here("data")
jagsdir <- here("jags")
analdir <- here("analysis")
savedir <- here("analysis/cache")
```

We also need a couple of helper functions.

```{r define_funcs}
## better round
Re2prec <- function(x, fun = "round", prec = 1) {
  ## 'fun' can be "round", "floor", or "ceiling"
  ## 'prec' is nearest value
  ## (eg, 0.1 is to nearest tenth; 1 is to nearest integer)
  if(prec<=0) { stop("\"prec\" cannot be less than or equal to 0") }
  do.call(map,list(x/prec))*prec
}
```

# User inputs

We begin by supplying values for the minimum and maximum ages of spawning adults, plus some information for the model code and evaluation.

```{r get_user_inputs}
## min & max adult age classes
age_min <- 3
age_max <- 6

## file where to save JAGS model
fn_jags <- "Willamette_Chin_SR_flow_models_mainstem_JAGS.txt"

## upper threshold for Gelman & Rubin's potential scale reduction factor (Rhat).
Rhat_thresh <- 1.1
```

Next we specify the names of four necessary data files containing the following information:
 
 1. observed total number of adult spawners (escapement) by year;
 2. observed age composition of adult spawners by year;
 3. observed total harvest by year;
 4. flow covariates by year.


```{r get_filenames}
## 1. file with escapement data
## [n_yrs x 2] matrix of obs counts; 1st col is calendar yr
fn_esc <- "chin_esc.csv"

## 2. file with age comp data
## [n_yrs x (1+A)]; 1st col is calendar yr
fn_age <- "chin_agecomp.csv"

## 3. file with harvest data
## [n_yrs x 2] matrix of obs catch; 1st col is calendar yr
fn_harv <- "chin_harv.csv"

## 3. file with harvest data
## [n_yrs x 2] matrix of obs catch; 1st col is calendar yr
fn_cov <- "Willamette_Chin_SR_mainstem_flow_covariates.csv"
```

# Loading the fish data

Here we load in the first three data files and do some simple calculations and manipulations.

First the spawner data:

```{r get_escapement_data}
## escapement
dat_esc <- read.csv(file.path(datadir, fn_esc))
## use total counts
dat_esc <- dat_esc[dat_esc$group=="total",-1]
## years of data
dat_yrs <- dat_esc$year
## number of years of data
n_yrs <- length(dat_yrs)
## get first & last years
yr_frst <- min(dat_yrs)
yr_last <- max(dat_yrs)
## log of escapement
ln_dat_esc <- log(dat_esc[,-1])
```

Next the age composition data:

```{r get_age_data}
## age comp data
dat_age <- read.csv(file.path(datadir, fn_age))
## drop first age_min rows; drop site & year col
dat_age <- dat_age[-(1:(age_min)), -1]
## num of age classes
A <- age_max-age_min+1
## total num of age obs by cal yr
dat_age[,"sum"] <- apply(dat_age,1,sum)
## row indices for any years with no obs age comp
idx_NA_yrs <- which(dat_age$sum<A, TRUE)
if(length(idx_NA_yrs) > 0) {
  ## replace 0's in yrs w/o any obs with NA's
  dat_age[idx_NA_yrs,(1:A)] <- NA
  ## change total in yrs w/o any obs from 0 to A to help dmulti()
  dat_age[idx_NA_yrs,"sum"] <- A
}
## convert class
dat_age <- as.matrix(dat_age)
```

And then the harvest data:

```{r get_harvest}
## harvest
dat_harv <- read.csv(file.path(datadir, fn_harv))
## trim to correct years & drop year col 
dat_harv <- dat_harv[dat_harv$year>=yr_frst & dat_harv$year<=yr_last,-1]
```

# Loading the covariates

```{r get_flow_cov}
cov_flow <- read.csv(file.path(datadir, fn_cov))
n_mods <- dim(cov_flow)[2] - 1
```


# Specifying model in JAGS

Now we can specify the model in JAGS. Note that the code below is not written to be universally generic with respect to the number of covariates, but rather to emphasize how to incorporate the three we used in this specific application. The important thing is the number of covariate parameters in the `PRIORS` and `LIKELIHOOD` sections (i.e., there must be a unique `c_Name` parameter for each of the _MM_ covariates).

```{r SSSR_in_JAGS}
cat("

model {
	
	##--------
	## PRIORS
	##--------
	## alpha = exp(a) = intrinsic productivity
	mu_Rkr_a ~ dnorm(0,1e-3)I(-4,4);
	alpha <- exp(mu_Rkr_a);
	E_Rkr_a <- mu_Rkr_a + var_Qr/(2 - 2*phi^2);

	## covariate effects
	c1 ~ dnorm(0,0.001)

	## strength of dens depend
	Rkr_b ~ dunif(0,0.01);

	## AR(1) coef for proc errors
	phi ~ dunif(-0.999,0.999);
	
	## process variance for recruits model
	sd_Qr ~ dunif(0.001,20);
	tau_Qr <- pow(sd_Qr,-2);
	var_Qr <- pow(sd_Qr,2)
	
	## innovation in first year
	innov_1 ~ dnorm(0,tau_Qr*(1-phi*phi));
	
	## obs variance for spawners
	sd_Rs ~ dunif(0.001,3);
	tau_Rs <- pow(sd_Rs,-2);
	var_Rs <- pow(sd_Rs,2)
	
	## unprojectable early recruits;
	## hyper mean across all popns
	Rec_mu ~ dnorm(0,0.001);
	## hyper SD across all popns
	Rec_sig ~ dunif(0,100);
	## precision across all popns
	Rec_tau <- pow(Rec_sig,-2);
	## multipliers for unobservable total runs
	ttl_run_mu ~ dunif(1,5);
	ttl_run_tau ~ dunif(1,20);
	
	## maturity schedule
	## unif vec for Dirch prior
	for(i in 1:A) { theta[i] <- 1 }
	## hyper-mean for maturity
	p_mu ~ ddirch(theta);
	## hyper-prec for maturity
	p_pi ~ dunif(0.001,1e3);
	for(t in 1:(n_yrs-age_min)) { p_vec[t,1:A] ~ ddirch(p_mu*p_pi) }
	
	##------------
	## LIKELIHOOD
	##------------
	## 1st brood yr requires different innovation
	## predicted recruits in BY t
	ln_Rkr_a[1] <- mu_Rkr_a + c1*covar[1];
	E_ln_Rec[1] <- ln_Sp[1] + ln_Rkr_a[1] - Rkr_b*Sp[1] + phi*innov_1;
	tot_ln_Rec[1] ~ dnorm(E_ln_Rec[1],tau_Qr);
	res_ln_Rec[1] <- tot_ln_Rec[1] - E_ln_Rec[1];
	## median of total recruits
	tot_Rec[1] <- exp(tot_ln_Rec[1]);

	## R/S
	ln_RS[1] <- tot_ln_Rec[1] - ln_Sp[1];
		
	## brood-yr recruits by age
	for(a in 1:A) {
		Rec[1,a] <- max(1,tot_Rec[1] * p_vec[1,a]);
		}
	
	## brood years 2:(n_yrs-age_min)
	for(t in 2:(n_yrs-age_min)) {
		## predicted recruits in BY t
		ln_Rkr_a[t] <- mu_Rkr_a + c1*covar[t];
		E_ln_Rec[t] <- ln_Sp[t] + ln_Rkr_a[t] - Rkr_b*Sp[t] + phi*res_ln_Rec[t-1];
		tot_ln_Rec[t] ~ dnorm(E_ln_Rec[t],tau_Qr);
		res_ln_Rec[t] <- tot_ln_Rec[t] - E_ln_Rec[t];
		## median of total recruits
		tot_Rec[t] <- exp(tot_ln_Rec[t]);
		## R/S
		ln_RS[t] <- tot_ln_Rec[t] - ln_Sp[t];
		## brood-yr recruits by age
		for(a in 1:A) {
			Rec[t,a] <- max(1,tot_Rec[t] * p_vec[t,a]);
			}
		} ## end t loop over year

	## get total cal yr returns for first age_min yrs
	for(i in 1:(age_min)) {
		ln_tot_Run[i] ~ dnorm(ttl_run_mu*Rec_mu,Rec_tau/ttl_run_tau);
		tot_Run[i] <- exp(ln_tot_Run[i]);
    }

	## get predicted calendar year returns by age
	## matrix Run has dim [(n_yrs-age_min) x A]
	## step 1: incomplete early broods
	## first cal yr of this grp is first brood yr + age_min
	for(i in 1:(age_max-age_min)) {
		## projected recruits
		for(a in 1:(i)) {
			Run[i,a] <- Rec[(age_skip+i)-a+1,a];
			}
		## imputed recruits
		for(a in (i+1):A) {
			lnRec[i,a] ~ dnorm(Rec_mu,Rec_tau);
			Run[i,a] <- exp(lnRec[i,a]);
			}
		## total run size
		tot_Run[i+age_min] <- sum(Run[i,1:A]);
		## predicted age-prop vec for multinom
		for(a in 1:A) {
			age_v[i,a] <- Run[i,a] / tot_Run[i+age_min];
			}
		## multinomial for age comp
		dat_age[i,1:A] ~ dmulti(age_v[i,1:A],dat_age[i,A+1]);
    lp_age[i] <- logdensity.multi(dat_age[i,1:A],age_v[i,1:A],dat_age[i,A+1]);
		}
	
	## step 2: info from complete broods
	## first cal yr of this grp is first brood yr + age_max
	for(i in A:(n_yrs-age_min)) {
		for(a in 1:A) {
			Run[i,a] <- Rec[(age_skip+i)-a+1,a];
			}
		## total run size
		tot_Run[i+age_min] <- sum(Run[i,1:A]);
		## predicted age-prop vec for multinom
		for(a in 1:A) {
			age_v[i,a] <- Run[i,a] / tot_Run[i+age_min];
			}
		## multinomial for age comp
		dat_age[i,1:A] ~ dmulti(age_v[i,1:A],dat_age[i,A+1]);
    lp_age[i] <- logdensity.multi(dat_age[i,1:A],age_v[i,1:A],dat_age[i,A+1]);
		}
		
	## get predicted calendar year spawners
	## first cal yr is first brood yr
	for(t in 1:(n_yrs)) {
		## obs model for spawners
    Sp[t] <- max(1,tot_Run[t] - dat_harv[t]);
		ln_Sp[t] <- log(Sp[t]);
		ln_dat_esc[t] ~ dnorm(ln_Sp[t], tau_Rs);
    lp_esc[t] <- logdensity.norm(ln_dat_esc[t],ln_Sp[t], tau_Rs)
		}
			
} ## end model description

", file=file.path(jagsdir, fn_jags))
```

***
# Fitting the model

The last thing we need to do before fitting the model in JAGS is to specify:

1. the data and indices that go into the model;
2. the model parameters and states that we want JAGS to return;
3. the MCMC control parameters.

Please note that the following code takes ~3 min to run on a quad-core machine with 3.5 GHz Intel processors.

```{r start_timer, include=FALSE}
## start timer
timer_start <- proc.time() 
```

```{r JAGS_IO, message=FALSE, warning=FALSE, cache=TRUE}
## 1. data to pass to JAGS
dat_jags <- c("dat_age","ln_dat_esc","dat_harv","covar",
              "n_yrs","A","age_min","age_max") 

## 2. model params/states for JAGS to return
par_jags <- c("alpha","E_Rkr_a","mu_Rkr_a","Rkr_b","ln_Rkr_a",
              "c1","lp_age","lp_esc",
              "Sp","Rec","tot_ln_Rec","ln_RS","p_vec",
              "var_Qr","var_Rs","res_ln_Rec")

## 3. MCMC control params
## MCMC parameters
mcmc_chains <- 4
mcmc_length <- 7e5
mcmc_burn <- 2e5
mcmc_thin <- 400
## total number of MCMC samples
mcmc_samp <- (mcmc_length-mcmc_burn)*mcmc_chains/mcmc_thin

## function to create JAGS inits
init_vals <- function() {
	list(mu_Rkr_a=1, c1=rnorm(1,0,0.1),
	     Rkr_b=1/exp(mean(ln_dat_esc, na.rm=TRUE)),
	     p_pi=1, p_mu=rep(1,A),
	     p_vec=matrix(c(0.04,0.50,0.45,0.01),n_yrs-age_min,A,byrow=TRUE),
	     Rec_mu=log(1000),
	     Rec_sig=0.1,
	     tot_ln_Rec=rep(log(1000),n_yrs-age_min),
	     sd_Rs=0.1,
	     innov_1=0,
	     phi=0.5)
	}

## fit the model in JAGS & store results
mod_fits <- vector("list", n_mods)
for(i in 1:n_mods) {
  covar <- (cov_flow[,i+1] - mean(cov_flow[,i+1])) / sd(cov_flow[,i+1])
  dat_jags <- c("dat_age","ln_dat_esc","dat_harv","covar",
                "n_yrs","A","age_min","age_max","age_skip","n_fore") 
  ## list of model info for JAGS
  mod_jags <- list(data = dat_jags,
                   inits = init_vals,
                   parameters.to.save = par_jags,
                   model.file = fn_jags,
                   n.chains = as.integer(mcmc_chains),
                   n.iter = as.integer(mcmc_length),
                   n.burnin = as.integer(mcmc_burn),
                   n.thin = as.integer(mcmc_thin),
                   DIC = TRUE)
  mod_fits[[i]] <- do.call(jags.parallel, mod_jags)
}
# save(list=ls(), file="Willamette_Chin_SR_flow_models_mainstem.RData")
```

```{r stop_timer, include=FALSE}
## stop timer
run_time_in_min <- round(((proc.time()-timer_start)/60)["elapsed"], 1)
cat(run_time_in_min, file="run_time_in_min.txt")
```

# Finding the best model

Let's examine Watanabe's Akaike Information Criterion (WAIC) for each of the models to see which of the covariate scenarios seems to be best supported by the available data.

```{r get_WAIC}
WAIC <- vector("numeric",n_mods)
cc_smry_1 <- matrix(NA,n_mods,3)
colnames(cc_smry_1) <- paste0("linr_",c("lo","med","up"))
## extract log densities from JAGS objects
for(i in 1:n_mods) {
  ldens <- cbind(matrix(0,mcmc_samp,(age_min)),
                 mod_fits[[i]]$BUGSoutput$sims.list$lp_age)
  ldens <- ldens + mod_fits[[i]]$BUGSoutput$sims.list$lp_esc
  WAIC[i] <- waic(ldens)$waic
  cc_smry_1[i,] <- mod_fits[[i]]$BUGSoutput$summary["c1", c("2.5%","50%","97.5%")]
}
d_WAIC <- round(WAIC-min(WAIC),1)
wt_WAIC <- exp(-0.5*d_WAIC)/sum(exp(-0.5*d_WAIC))
tbl_WAIC <- data.frame(life_stage=flow_meta$life_stage,
                       variable=sub(" of 7-day mean","",flow_meta$long_name),
                       begin=flow_meta$begin,
                       end=flow_meta$end,
                       lag=flow_meta$lag_1,
                       WAIC=round(WAIC,1),
                       d_WAIC=d_WAIC,
                       wt_WAIC=round(wt_WAIC,3),
                       round(cc_smry_1,2))
write.csv(tbl_WAIC,  row.names = FALSE,
          file = "Willamette_Chin_SR_flow_models_mainstem_model_selection_R_linear.csv")
best_idx <- which(tbl_WAIC$d_WAIC==0)
tbl_WAIC[,!(names(tbl_WAIC) %in% c("lag","WAIC"))]
```

The model with the most support from the data is number `r best_idx`, which estimates a flow effect during the `r tbl_WAIC$life_stage[best_idx]` stage as the "`r tbl_WAIC$variable[best_idx]`" beginning on `r tbl_WAIC$begin[best_idx]` and ending on `r tbl_WAIC$end[best_idx]`.

## Model-averaged effects

Rather than focus on a best model, we can evaluate model-averaged predicted productivity across the various life stages.

```{r mod_avg_flow_effects, eval=FALSE}
mm <- rep(tbl_WAIC$wt_WAIC[fs_idx], each=length(scen_sp)*n_yrs_scen)
tbl_fut_wtd <- mm * tbl_futures[,-c(1:3)]
wtd_avg <- 0
for(i in 1:nn) {
  wtd_avg <- wtd_avg + tbl_fut_wtd[(1:(length(scen_sp)*n_yrs_scen))+(i-1)*(length(scen_sp)*n_yrs_scen),]
}
wtd_avg <- cbind(year=rep(yrs_scen,each=length(scen_sp)),
                 spawners=rep(scen_sp,times=n_yrs_scen),
                 round(wtd_avg,2))
write.csv(wtd_avg, row.names = FALSE,
          file="Willamette_Chin_SR_flow_models_mainstem_model_avg_scenarios.csv")
```

## Diagnostics

Here is a histogram of the Gelman & Rubin statistics $(R_{hat})$ for the estimated parameters from the best model. Recall that we set an upper threshold of `r Rhat_thresh`, so any parameters with $(R_{hat})$ values larger than `r Rhat_thresh` deserve some additional inspection.

```{r model_diagnostics}
mod_fit <- mod_fits[[best_idx]]
## Rhat values for all parameters
rh <- mod_fit$BUGSoutput$summary[,"Rhat"]
## histogram of Rhat values for all parameters
par(mai=c(0.9,0.9,0.3,0.1))
hist(rh, breaks=seq(0.99,ceiling(max(rh)/0.01)*0.01,by=0.01),main="",
     col=rgb(0,0,255,alpha=50,maxColorValue=255),border="blue3",xlab=expression(italic(R[hat])))
## Rhat values > threshold
bad_Rhat <- rh[rh>Rhat_thresh]
## prop of params with Rhat > threshold
round(length(bad_Rhat)/length(rh),3)
## param names
par_names <- sub("\\[.*","",names(bad_Rhat))
## number of Rhat > threshold by param name
table(par_names)
## index values for offenders
idx <- as.integer(sub("(^.*\\[)([0-9]{1,3})(.*)","\\2",names(bad_Rhat)))
## data frame of offenders
(df <- data.frame(par=par_names, index=idx))
```

The convergence statistics indicate that some of the elements in $p$ for the estimated proportions of the youngest and oldest age classes (i.e., 3 and 8, respectively) did not converge to our desired threshold. However, there is very little data to inform those parameters, so we should not be too concerned.



# Model diagnostics

Here is a table of the Gelman & Rubin statistics $(R_{hat})$ for the estimated parameters. Recall that we set an upper threshold of `r Rhat_thresh`, so values larger than that deserve some additional inspection.

```{r model_diagnostics, eval=FALSE}
## params of interest
par_conv <- c("alpha","beta",paste0("gamma[",seq(4),"]"),
              "sigma_r","sigma_s","pi_tau",paste0("pi_eta[",seq(A-1),"]"))
## Gelman-Rubin
gelman.diag(best_fit[,par_conv])
## Autocorrelation
t(round(autocorr.diag(best_fit[,par_conv],
                      lags = seq(mcmc_ctrl$thin, 4*mcmc_ctrl$thin, mcmc_ctrl$thin),
                      relative=FALSE), 2))
```
