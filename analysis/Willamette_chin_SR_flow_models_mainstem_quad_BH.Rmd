---
title: Analysis of environmental effects on Chinook salmon from the Willamette River basin
output:
  html_document:
    fig_caption: yes
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
    number_sections: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r set_options, echo=FALSE, cache=TRUE}
options(width = 120, noaakey = "FgJgzuqMqUeHAyLBIDMNtcTAFcfInuqa")
```

***

[__Mark D. Scheuerell__](https://faculty.washington.edu/scheuerl/)  
_Fish Ecology Division, Northwest Fisheries Science Center, National Marine Fisheries Service, National Oceanic and Atmospheric Administration, Seattle, WA USA, mark.scheuerell@noaa.gov_

__J. Tyrell Deweber__  
_Oregon Cooperative Fish & Wildlife Research Unit, Department of Fisheries & Wildlife, Oregon State University, Corvallis, OR USA, Jefferson.Deweber@oregonstate.edu_

__Tom Friesen__  
_Oregon Department of Fish and Wildlife, Corvallis, OR USA, tom.friesen@oregonstate.edu_

***

This is version `r paste0('0.',format(Sys.time(), '%y.%m.%d'))`.

***

# Requirements
All analyses require the [R software](https://cran.r-project.org/) (v3.3+) for data retrieval, data processing, and summarizing model results, and the [JAGS software](http://mcmc-jags.sourceforge.net/) (v4.2.0) for Markov chain Monte Carlo (MCMC) simulation. Please note that some of the R code below may not work with older versions of JAGS due to some changes in the ways that arrays are handled.

We also need a few packages that are not included with the base installation of R, so we begin by installing them (if necessary) and then loading them.

```{r load_pkgs, message=FALSE, warning=FALSE}
if(!require("EGRET")) {
  install.packages("EGRET")
  library("EGRET")
}
if(!require("R2jags")) {
  install.packages("R2jags")
  library("R2jags")
}
if(!require("RCurl")) {
  install.packages("RCurl")
  library("RCurl")
}
if(!require("gsl")) {
  install.packages("gsl")
  library("gsl")
}
if(!require("reshape2")) {
  install.packages("reshape2")
  library("reshape2")
}
if(!require("viridis")) {
  install.packages("viridis")
  library("viridis")
}
```

# User inputs

We begin by specifying the names of three necessary data files that contain the following information:
 
 1. observed total number of adult spawners (escapement) by year;
 2. observed age composition of adult spawners by year;
 3. observed total harvest by year;
 4. metadata for the covariates.
 
The metadata for the covariates is a .csv file with the following columns:

1. `spp`: the species to which the covariate applies
2. `life_stage`: life stage at which the effect is thought to occur
3. `covariate`: type of covariate (e.g., flow, temperature)
4. `code`: USGS code for data type (i.e., usually 5-digit integer)
5. `long_name`: long name for the covariate
6. `short_name`: function name to derive the covariate
7. `lag_1`: years to lag begin date
8. `lag_2`: years to lag end date
9. `begin`: beginning date as 2-digit text (ie, mo-yr)
10. `end`: ending date as 2-digit text (ie, mo-yr)
11. `location`: description of location
12. `gage`: USGS gage number
13. `flag`: flag to include (1) or exclude (0) the covariate
14. `flow_scen`: flag to include (1) or exclude (0) flow scenario
15. `group`: integer indicator for life stage grouping

Let's also define the following parameters, which will be referenced throughout the analysis.

 * `n_yrs`: number of calendar years of data
 * `A`: number of age classes 
 * `M`: number of covariates

```{r get_user_inputs_1}
## 1. file with escapement data
## [n_yrs x 2] matrix of obs counts; 1st col is calendar yr
fn_esc <- "chin_esc.csv"

## 2. file with age comp data
## [n_yrs x (1+A)]; 1st col is calendar yr
fn_age <- "chin_agecomp.csv"
## min & max ages
age_min <- 3
age_max <- 6
## years, if any, of age-comp to skip; see below
age_skip <- 0

## 3. file with harvest data
## [n_yrs x 2] matrix of obs catch; 1st col is calendar yr
fn_harv <- "chin_harv.csv"

## 4. covariate metadata
cov_meta_file <- "chin_cov_metadata.csv"

## URL for example data files
## set to NULL if using a local folder/directory
ex_url <- "https://raw.githubusercontent.com/mdscheuerell/willamette/master/data/"
```

Next we specify some additional information regarding scenarios and forecasting, if desired.

```{r get_user_inputs_2}
## number of years of forecasts
n_fore <- 1

## file where to save JAGS model
fn_jags <- "Willamette_Chin_SR_flow_models_mainstem_JAGS_quad_BH.txt"

## upper threshold for Gelman & Rubin's (1992) potential scale reduction factor (Rhat).
Rhat_thresh <- 1.1

## threshold values for CI's
CI_vec <- c(0.025,0.5,0.975)

## FLOW SCENARIOS
## dir with flow scenarios
scen_dir <- "WBR_ScenarioPreds_06Mar2017"
## scenario names
scen_names <- c("unregulated","BiOp","lowApril","Recess",
                "LowRecess","BiOpTrib","LowSummer","NMFS1",
                "Corps1","Corps2","OSU1")
## spawner abundances to consider
scen_sp <- c(5,10,15,20)*1000
## first year of scenarios
scen_yr_frst <- 1929
## last year of scenarios
scen_yr_last <- 2007
```

# Function definitions

```{r func_defns}
## Re2prec
## converts any real number to round/floor/ceiling
Re2prec <- function(x,map="round",prec=1) {
  ## 'map' can be round, floor, or ceiling
  ## 'prec' is nearest value (eg, 0.1 means to nearest tenth); default 1 gives normal behavior
  if(prec<=0) { stop("\"prec\" cannot be less than or equal to 0") }
  do.call(map,list(x/prec))*prec
}

## over90k
## returns the total number of days that flow exceeded 90k cfs
over90k <- function(x) {
  return(sum(x >= 90000))
}

## min7mean
## returns the min of 7-day means over period
min7mean <- function(x) {
  return(round(min(filter(x, rep(1,7)/7, "convolution", sides=1), na.rm=TRUE),0))
}

## max7mean
## returns the max of 7-day means over period
max7mean <- function(x) {
  return(round(max(filter(x, rep(1,7)/7, "convolution", sides=1), na.rm=TRUE),0))
}

## med7mean
## returns the max of 7-day means over period
med7mean <- function(x) {
  return(round(median(filter(x, rep(1,7)/7, "convolution", sides=1), na.rm=TRUE),0))
}

## rng7mean
## returns the max of 7-day means over period
rng7mean <- function(x) {
  return(round(diff(range(filter(x, rep(1,7)/7, "convolution", sides=1), na.rm=TRUE)),0))
}

## range2
## returns the range as a scalar = max-min
range2 <- function(x) {
  return(diff(range(x)))
}

## DD15
## returns the cumulative number of degree days > 15C
DD15 <- function(x) {
  return(sum(filter(x, rep(1,7)/7, "convolution", sides=1) >= 15, na.rm=TRUE))
}

## colVars; from Gelman
## returns the column-wise variance of a matrix
colVars <- function(a) {
	n <- dim(a)[[1]]
	c <- dim(a)[[2]]
	mm <- matrix(.colMeans(a, n, c), n, c, byrow = TRUE)
	return(.colMeans(((a - mm) ^ 2), n, c) * n / (n - 1))
}

## waic; from Gelman
## computes WAIC based on pointwise log-like
waic <- function(log_lik) {
  S <- nrow(log_lik)
  n <- ncol(log_lik)
  lpd <- log(colMeans(exp(log_lik)))
  p_waic <- colVars(log_lik)
  elpd_waic <- lpd - p_waic
  waic <- -2*elpd_waic
  loo_weights_raw <- 1/exp(log_lik-max(log_lik))
  loo_weights_normalized <- loo_weights_raw /
    matrix(colMeans(loo_weights_raw),nrow=S,ncol=n,byrow=TRUE)
  loo_weights_regularized <- pmin(loo_weights_normalized, sqrt(S))
  elpd_loo <- log(colMeans(exp(log_lik)*loo_weights_regularized) /
                    colMeans(loo_weights_regularized))
  p_loo <- lpd - elpd_loo
  pointwise <- cbind(waic,lpd,p_waic,elpd_waic,p_loo,elpd_loo)
  total <- colSums(pointwise)
  se <- sqrt(n*colVars(pointwise))
  return(list(waic=total["waic"],
              elpd_waic=total["elpd_waic"],
              p_waic=total["p_waic"],
              elpd_loo=total["elpd_loo"],
              p_loo=total["p_loo"],
              pointwise=pointwise,
              total=total,
              se=se))
}
```


# Loading the fish data

Here we load in the first three data files and do some simple calculations and manipulations.

First the spawner data:

```{r get_escapement_data}
## escapement
dat_esc <- read.csv(text = getURL(paste0(ex_url,fn_esc)))
## use total counts
dat_esc <- dat_esc[dat_esc$group=="total",-1]
## inspect
dat_esc
## years of data
dat_yrs <- dat_esc$year
## number of years of data
n_yrs <- length(dat_yrs)
## get first & last years
yr_frst <- min(dat_yrs)
yr_last <- max(dat_yrs)
## log of escapement
ln_dat_esc <- c(log(dat_esc[,-1]),rep(NA,n_fore))
```

Next the age composition data:

```{r get_age_data}
## age comp data
dat_age <- read.csv(text = getURL(paste0(ex_url,fn_age)))
## use total age counts by year
dat_age <- dat_age[dat_age$site=="all" & dat_age$year>=yr_frst & dat_age$year<=yr_last,]
## drop first age_min+age_skip rows; drop site & year col
dat_age <- dat_age[-(1:(age_min+age_skip)),-c(1,2)]
## num of age classes
A <- age_max-age_min+1
## add row(s) of NA's for forecast years
dat_age <- rbind(dat_age,matrix(0,n_fore,A,dimnames=list(n_yrs+seq(n_fore),colnames(dat_age))))
## total num of age obs by cal yr
dat_age[,"sum"] <- apply(dat_age,1,sum)
## row indices for any years with no obs age comp
idx_NA_yrs <- which(dat_age$sum<A,TRUE)
## replace 0's in yrs w/o any obs with NA's
dat_age[idx_NA_yrs,(1:A)] <- NA
## change total in yrs w/o any obs from 0 to A to help dmulti()
dat_age[idx_NA_yrs,"sum"] <- A
## convert class
dat_age <- as.matrix(dat_age)
## inspect
dat_age
```

And then the harvest data:

```{r get_harvest}
## harvest
dat_harv <- read.csv(text = getURL(paste0(ex_url,fn_harv)))
## trim to correct years & drop year col 
dat_harv <- c(dat_harv[dat_harv$year>=yr_frst & dat_harv$year<=yr_last,-1],rep(0,n_fore))
```

# Loading the covariates

The analyses are based upon several environmental indicators related to river discharge and temperature. Load the data file containing all of the metadata regarding the specific covariates to be used.

```{r get_cov_meta}
cov_meta <- read.csv(text = getURL(paste0(ex_url,cov_meta_file)), stringsAsFactors = FALSE)
cov_meta$code <- gsub("\"","",cov_meta$code)
cov_meta$begin <- gsub("\"","",cov_meta$begin)
cov_meta$end <- gsub("\"","",cov_meta$end)
```

We need to define the beginning and ending dates for the covariates

```{r get_dates}
yr1 <- yr_frst
yr2 <- yr_last - age_min + n_fore
## start date
startDate <- paste0(yr1 + min(cov_meta$lag_1),"-01-01")
## end date
endDate <- paste0(yr2 + max(cov_meta$lag_2),"-12-31")
```

## River discharge

We begin by getting the daily flow data from the US Geological Service [National Water Information System](http://waterdata.usgs.gov/nwis) for the complete time period of interest.

```{r flow_info, message=FALSE, results="hold", cache=TRUE}
## metadata for flow covariates
flow_meta <- subset(cov_meta, covariate=="flow" & flag==1)
## data to get: flow (cfs)
parameterCD <- "00060"
## get all flow data for period of interest & gages
gages <- unique(flow_meta$gage)
n_gages <- length(gages)
tmp <- readNWISDaily(gages[1], parameterCD, startDate, endDate, convert=FALSE)
tmp$yr <- floor(tmp$DecYear)
flow_data <- tmp[,c("Date","waterYear","yr","Month","Day")]
colnames(flow_data) <- c("date","H2Oyr","yr","mon","day")
flow_data[,as.character(gages[1])] <- tmp$Q
if(n_gages > 1) {
  for(i in 2:n_gages) {
    tmp <- readNWISDaily(gages[i], parameterCD, startDate, endDate, convert=FALSE)
    flow_data[,as.character(gages[i])] <- tmp$Q
  }
}
```

Now we can extract the specific flow covariates that relate to each of the hypotheses about the affected life stage.

```{r get_flow_cov, cache=TRUE}
cov_flow <- matrix(NA,length(seq(yr1,yr2)),dim(flow_meta)[1]+1)
n_mods <- dim(cov_flow)[2] - 1
cov_flow[,1] <- seq(yr_frst,yr2)
for(i in 1:dim(flow_meta)[1]) {
  fn <- get(flow_meta[i,"short_name"])
  cnt <- 1
  for(t in yr1:yr2) {
    beg <- paste0(t+flow_meta[i,"lag_1"],"-",flow_meta[i,"begin"])
    end <- paste0(t+flow_meta[i,"lag_2"],"-",flow_meta[i,"end"])
    tmp <- flow_data[flow_data$date>=beg & flow_data$date<=end, as.character(flow_meta[i,"gage"])]
    cov_flow[cnt,i+1] <- fn(tmp)
    cnt <- cnt+1
  }
}
print(round(cov_flow,0))
write.csv(cov_flow, row.names = FALSE,
          file="Willamette_Chin_SR_flow_models_mainstem_covariates.csv")
```

Here are plots of the pairwise correlation coefficients for each of the flow covariates.

```{r plot_cov_corr, fig.width=8, fig.height=7.5}
## min cor to consider
thrsh <- 0.7
## color palette
clr <- viridis(n=11, begin=0.1, end=0.9, option="B")
## transformed matrix of corr coefs
tcc <- t(apply(cor(cov_flow[,-1]),1,rev))
nn <- dim(tcc)[1]
par(mai=rep(0.5,4), omi=c(0,0,0,0.5))
## color image
image(tcc, xaxt="n", yaxt="n", col=clr)
axis(1,at=(seq(0,nn,length.out=nn)+1/nn)/nn, labels=seq(nn), cex.axis=0.7, tick=FALSE, line=-1)
axis(2,at=rev(seq(0,nn,length.out=nn)+1/nn)/nn, labels=seq(nn), las=1, cex.axis=0.7, tick=FALSE, line=-0.8)
axis(3,at=(seq(0,nn,length.out=nn)+1/nn)/nn, labels=seq(nn), cex.axis=0.7, tick=FALSE, line=-1)
axis(4,at=rev(seq(0,nn,length.out=nn)+1/nn)/nn, labels=seq(nn), las=1, cex.axis=0.7, tick=FALSE, line=-0.8)
grid(nx=n_mods,ny=n_mods, lty="solid")
## show major breaks by life stage
bls <- cumsum(table(cov_meta$group))[-length(unique(cov_meta$group))] + 1
abline(h=seq(par()$usr[1],par()$usr[2],length.out=nn+1)[nn-bls+2], lwd=4, col="white")
abline(v=seq(par()$usr[1],par()$usr[2],length.out=nn+1)[bls], lwd=4, col="white")
## add legend
legend(x="right", legend=rev(seq(0,10)/10), title="Corr",
	   inset=c(-0.15,0), xpd=NA,
	   col=rev(viridis(n=11, begin=0.1, end=0.9, option="B")), bg="white",
	   pch=15, pt.cex=1.2, cex=0.7, bty="n")
```

## Water temperature

Next we get the daily temperature data from the US Geological Service [National Water Information System](http://waterdata.usgs.gov/nwis) for the complete time period of interest.

```{r temp_info, message=FALSE, results="hold", cache=TRUE, eval=FALSE}
## metadata for flow covariates
temp_meta <- subset(cov_meta, covariate=="temp" & flag==1)
## data to get: temp (C)
parameterCD <- "00010"
## get all flow data for period of interest & gages
gages <- unique(temp_meta$gage)
n_gages <- length(gages)
tmp <- readNWISDaily(gages[1], parameterCD, startDate, endDate, convert=FALSE)
tmp$yr <- floor(tmp$DecYear)
temp_data <- tmp[,c("Date","waterYear","yr","Month","Day")]
colnames(temp_data) <- c("date","H2Oyr","yr","mon","day")
temp_data[,as.character(gages[1])] <- tmp$Q
if(n_gages > 1) {
  for(i in 2:n_gages) {
    tmp <- readNWISDaily(gages[i], parameterCD, startDate, endDate, convert=FALSE)
    flow_data[,as.character(gages[i])] <- tmp$Q
  }
}
```

Now we can extract the specific temperature covariates that relate to each of the hypotheses about the affected life stage.

```{r get_temp_cov, cache=TRUE, eval=FALSE}
cov_temp <- matrix(NA,length(seq(yr1,yr2)),dim(temp_meta)[1]+1)
cov_temp[,1] <- seq(yr_frst,yr2)
for(i in 1:dim(temp_meta)[1]) {
  fn <- get(temp_meta[i,"short_name"])
  cnt <- 1
  for(t in yr1:yr2) {
    beg <- paste0(t+temp_meta[i,"lag_1"],"-",temp_meta[i,"begin"])
    end <- paste0(t+temp_meta[i,"lag_2"],"-",temp_meta[i,"end"])
    tmp <- temp_data[temp_data$date>=beg & temp_data$date<=end, as.character(temp_meta[i,"gage"])]
    if(length(tmp)>0) {
      cov_temp[cnt,i+1] <- fn(tmp)
    } else {
      cov_temp[cnt,i+1] <- NA
    }
    cnt <- cnt+1
  }
}
cov_temp
```

Unfortunately, there are missing years of temperature data, even at the Portland gage.

# Specifying the model in JAGS

```{r JAGS_BH_cov_AR}
cat("

model {
  
  ##--------
  ## PRIORS
  ##--------
  ## alpha = exp(a) = intrinsic productivity
  alpha ~ dunif(0.1,100);
  mu_BH_a <- log(alpha);
  E_BH_a <- mu_BH_a + sigma_r/2;
  
  ## strength of dens depend
  beta ~ dunif(0,0.01);
  
  ## covariate effects
  # for(i in 1:n_cov) { gamma[i] ~ dnorm(0,0.001) }
  c1 ~ dnorm(0,0.001)
  c2 ~ dnorm(0,0.001)
  
  ## AR(1) coef for proc errors
  phi ~ dunif(-0.999,0.999);
  
  ## innovation in first year
  innov_1 ~ dnorm(0,tau_r*(1-phi*phi));
  
  ## process variance for recruits model
  sd_r ~ dunif(0.001,20);
  tau_r <- pow(sd_r,-2);
  sigma_r <- pow(sd_r,2);
  
  ## obs variance for spawners
  sd_s ~ dunif(0.001,20);
  tau_s <- pow(sd_s,-2);
  sigma_s <- pow(sd_s,2);
  
  ## unprojectable early recruits;
  ## hyper mean across all popns
  Rec_mu ~ dnorm(0,0.001);
  ## hyper SD across all popns
  Rec_sig ~ dunif(0,100);
  ## precision across all popns
  Rec_tau <- pow(Rec_sig,-2);
  ## multipliers for unobservable total runs
  ttl_run_mu ~ dunif(1,5);
  ttl_run_tau ~ dunif(1,20);
  
  ## maturity schedule
  ## unif vec for Dirch prior
  for(i in 1:A) { theta[i] <- 1 }
  ## hyper-mean for maturity
  pi_eta ~ ddirch(theta);
  ## hyper-prec for maturity
  pi_tau ~ dunif(0.001,1e3);
  for(t in 1:(n_yrs-age_min+n_fore)) { pi_vec[t,1:A] ~ ddirch(pi_eta*pi_tau) }
  
  ##------------
  ## LIKELIHOOD
  ##------------
  ## predicted recruits in BY t
  # covar[1] <- inprod(gamma,scl_cvrs[1,]);
  e_covar[1] <- c1*covar[1] + c2*covar[1]^2;
  ln_BH_a[1] <- mu_BH_a + e_covar[1]; 
  E_ln_Rec[1] <- ln_BH_a[1] + ln_Sp[1] - log(1 + beta*Sp[1]) + phi*innov_1;
  tot_ln_Rec[1] ~ dnorm(E_ln_Rec[1],tau_r);
  res_ln_Rec[1] <- tot_ln_Rec[1] - E_ln_Rec[1];
  ## median of total recruits
  tot_Rec[1] <- exp(tot_ln_Rec[1]);
  
  ## R/S
  ln_RS[1] <- tot_ln_Rec[1] - ln_Sp[1];
  
  ## brood-yr recruits by age
  for(a in 1:A) {
    Rec[1,a] <- max(1,tot_Rec[1] * pi_vec[1,a]);
  }
  
  ## brood years 2:(n_yrs-age_min)
  for(t in 2:(n_yrs-age_min+n_fore)) {
    ## predicted recruits in BY t
    # covar[t] <- inprod(gamma, scl_cvrs[t,]);
    e_covar[t] <- c1*covar[t] + c2*covar[t]^2;
    ln_BH_a[t] <- mu_BH_a + e_covar[t]; 
    E_ln_Rec[t] <- ln_BH_a[t] + ln_Sp[t] - log(1 + beta*Sp[t]) + phi*(res_ln_Rec[t-1]);
    tot_ln_Rec[t] ~ dnorm(E_ln_Rec[t],tau_r);
    res_ln_Rec[t] <- tot_ln_Rec[t] - E_ln_Rec[t];
    ## median of total recruits
    tot_Rec[t] <- exp(tot_ln_Rec[t]);
    ## R/S
    ln_RS[t] <- tot_ln_Rec[t] - ln_Sp[t];
    ## brood-yr recruits by age
    for(a in 1:A) {
      Rec[t,a] <- max(1,tot_Rec[t] * pi_vec[t,a]);
    }
  } ## end t loop over year
  
  ## get total cal yr returns for first age_min yrs
  for(i in 1:(age_min+age_skip)) {
    ln_tot_Run[i] ~ dnorm(ttl_run_mu*Rec_mu,Rec_tau/ttl_run_tau);
    tot_Run[i] <- exp(ln_tot_Run[i]);
  }
  
  ## get predicted calendar year returns by age
  ## matrix Run has dim [(n_yrs-age_min) x A]
  ## step 1: incomplete early broods
  ## first cal yr of this grp is first brood yr + age_min + age_skip
  for(i in 1:(age_max-age_min-age_skip)) {
    ## projected recruits
    for(a in 1:(i+age_skip)) {
      Run[i,a] <- Rec[(age_skip+i)-a+1,a];
    }
    ## imputed recruits
    for(a in (i+1+age_skip):A) {
      lnRec[i,a] ~ dnorm(Rec_mu,Rec_tau);
      Run[i,a] <- exp(lnRec[i,a]);
    }
    ## total run size
    tot_Run[i+age_min+age_skip] <- sum(Run[i,1:A]);
    # predicted age-prop vec for multinom
    for(a in 1:A) {
      age_v[i,a] <- Run[i,a] / tot_Run[i+age_min];
    }
    ## multinomial for age comp
    dat_age[i,1:A] ~ dmulti(age_v[i,1:A],dat_age[i,A+1]);
    lp_age[i] <- logdensity.multi(dat_age[i,1:A],age_v[i,1:A],dat_age[i,A+1]);
  }
  
  ## step 2: info from complete broods
  ## first cal yr of this grp is first brood yr + age_max
  for(i in (A-age_skip):(n_yrs-age_min-age_skip+n_fore)) {
    for(a in 1:A) {
      Run[i,a] <- Rec[(age_skip+i)-a+1,a];
    }
    ## total run size
    tot_Run[i+age_min+age_skip] <- sum(Run[i,1:A]);
    ## predicted age-prop vec for multinom
    for(a in 1:A) {
      age_v[i,a] <- Run[i,a] / tot_Run[i+age_min];
    }
    ## multinomial for age comp
    dat_age[i,1:A] ~ dmulti(age_v[i,1:A],dat_age[i,A+1]);
    lp_age[i] <- logdensity.multi(dat_age[i,1:A],age_v[i,1:A],dat_age[i,A+1]);
  }
  
  ## get predicted calendar year spawners
  ## first cal yr is first brood yr
  for(t in 1:(n_yrs+n_fore)) {
    ## obs model for spawners
    Sp[t] <- max(1,tot_Run[t] - dat_harv[t]);
    ln_Sp[t] <- log(Sp[t]);
    ln_dat_esc[t] ~ dnorm(ln_Sp[t], tau_s);
    lp_esc[t] <- logdensity.norm(ln_dat_esc[t],ln_Sp[t], tau_s);
  }
  
} ## end model description

", file=fn_jags)
```

***
# Fitting the model

The last thing we need to do before fitting the model in JAGS is to specify:

1. the data and indices that go into the model;
2. the model parameters and states that we want JAGS to return;
3. the MCMC control parameters.

Please note that the following code takes ~3 min to run on a quad-core machine with 3.5 GHz Intel processors.

```{r start_timer, include=FALSE}
## start timer
timer_start <- proc.time() 
```

```{r JAGS_IO, message=FALSE, warning=FALSE, cache=TRUE}
## 1. data to pass to JAGS
## see below

## 2. model params/states for JAGS to return
par_jags <- c("alpha","E_BH_a","ln_BH_a",
              "beta",
              "c1", "c2",
              "lp_age","lp_esc",
              "Sp","Rec","tot_ln_Rec","ln_RS",
              "pi_vec",
              "sigma_r","sigma_s","res_ln_Rec")

## 3. MCMC control params
## MCMC parameters
mcmc_chains <- 4
mcmc_length <- 4.5e5
mcmc_burn <- 2e5
mcmc_thin <- 200
## total number of MCMC samples
mcmc_samp <- (mcmc_length-mcmc_burn)*mcmc_chains/mcmc_thin

## function to create JAGS inits
init_vals <- function() {
	list(mu_Rkr_a=1, c1=rnorm(1,0,0.1), c2=rnorm(1,0,0.1),
	     Rkr_b=1/exp(mean(ln_dat_esc, na.rm=TRUE)),
	     p_pi=1, p_mu=rep(1,A),
	     p_vec=matrix(c(0.04,0.50,0.45,0.01),n_yrs-age_min+n_fore,A,byrow=TRUE),
	     Rec_mu=log(1000),
	     Rec_sig=0.1,
	     tot_ln_Rec=rep(log(1000),n_yrs-age_min+n_fore),
	     sd_Rs=0.1,
	     innov_1=0,
	     phi=0.5)
	}

## fit the model in JAGS & store results
mod_fits <- vector("list", n_mods)
for(i in 1:n_mods) {
  covar <- (cov_flow[,i+1]-mean(cov_flow[,i+1]))/sd(cov_flow[,i+1])
  dat_jags <- c("dat_age","ln_dat_esc","dat_harv","covar",
                "n_yrs","A","age_min","age_max","age_skip","n_fore") 
  ## list of model info for JAGS
  mod_jags <- list(data=dat_jags,
                   inits=init_vals,
                   parameters.to.save=par_jags,
                   model.file=fn_jags,
                   n.chains=as.integer(mcmc_chains),
                   n.iter=as.integer(mcmc_length),
                   n.burnin=as.integer(mcmc_burn),
                   n.thin=as.integer(mcmc_thin),
                   DIC=TRUE)
  mod_fits[[i]] <- do.call(jags.parallel, mod_jags)
}
save(list=ls(), file="Willamette_Chin_SR_flow_models_mainstem.RData")
```

```{r stop_timer, include=FALSE}
## stop timer
run_time_in_min <- round(((proc.time()-timer_start)/60)["elapsed"], 1)
cat(run_time_in_min, file="run_time_in_min.txt")
```

# Finding the best model

Let's examine Watanabe's Akaike Information Criterion (WAIC) for each of the models to see which of the covariate scenarios seems to be best supported by the available data.

```{r get_WAIC}
WAIC <- vector("numeric",n_mods)
cc_smry_1 <- matrix(NA,n_mods,3)
cc_smry_2 <- matrix(NA,n_mods,3)
colnames(cc_smry_1) <- paste0("linr_",c("lo","med","up"))
colnames(cc_smry_2) <- paste0("quad_",c("lo","med","up"))
## extract log densities from JAGS objects
for(i in 1:n_mods) {
  ldens <- cbind(matrix(0,mcmc_samp,(age_min+age_skip)),
                 mod_fits[[i]]$BUGSoutput$sims.list$lp_age)
  ldens <- ldens + mod_fits[[i]]$BUGSoutput$sims.list$lp_esc
  WAIC[i] <- waic(ldens)$waic
  cc_smry_1[i,] <- mod_fits[[i]]$BUGSoutput$summary["c1", c("2.5%","50%","97.5%")]
  cc_smry_2[i,] <- mod_fits[[i]]$BUGSoutput$summary["c2", c("2.5%","50%","97.5%")]
}
d_WAIC <- round(WAIC-min(WAIC),1)
wt_WAIC <- exp(-0.5*d_WAIC)/sum(exp(-0.5*d_WAIC))
tbl_WAIC <- data.frame(life_stage=flow_meta$life_stage,
                       variable=sub(" of 7-day mean","",flow_meta$long_name),
                       begin=flow_meta$begin,
                       end=flow_meta$end,
                       lag=flow_meta$lag_1,
                       WAIC=round(WAIC,1),
                       d_WAIC=d_WAIC,
                       wt_WAIC=round(wt_WAIC,3),
                       round(cc_smry_1,2),
                       round(cc_smry_2,2))
write.csv(tbl_WAIC,  row.names = FALSE,
          file = "Willamette_Chin_SR_flow_models_mainstem_model_selection_all.csv")
best_idx <- which(tbl_WAIC$d_WAIC==0)
tbl_WAIC[,!(names(tbl_WAIC) %in% c("lag"))]
```

The model with the most support from the data is number `r best_idx`, which estimates a flow effect during the `r tbl_WAIC$life_stage[best_idx]` stage as the "`r tbl_WAIC$variable[best_idx]`" beginning on `r tbl_WAIC$begin[best_idx]` and ending on `r tbl_WAIC$end[best_idx]`.

## Model-averaged effects

Rather than focus on a best model, we can evaluate model-averaged predicted productivity across the various life stages.

```{r mod_avg_flow_effects, eval=FALSE}
mm <- rep(tbl_WAIC$wt_WAIC[fs_idx], each=length(scen_sp)*n_yrs_scen)
tbl_fut_wtd <- mm * tbl_futures[,-c(1:3)]
wtd_avg <- 0
for(i in 1:nn) {
  wtd_avg <- wtd_avg + tbl_fut_wtd[(1:(length(scen_sp)*n_yrs_scen))+(i-1)*(length(scen_sp)*n_yrs_scen),]
}
wtd_avg <- cbind(year=rep(yrs_scen,each=length(scen_sp)),
                 spawners=rep(scen_sp,times=n_yrs_scen),
                 round(wtd_avg,2))
write.csv(wtd_avg, row.names = FALSE,
          file="Willamette_Chin_SR_flow_models_mainstem_model_avg_scenarios.csv")
```

## Diagnostics

Here is a histogram of the Gelman & Rubin statistics $(R_{hat})$ for the estimated parameters from the best model. Recall that we set an upper threshold of `r Rhat_thresh`, so any parameters with $(R_{hat})$ values larger than `r Rhat_thresh` deserve some additional inspection.

```{r model_diagnostics}
mod_fit <- mod_fits[[best_idx]]
## Rhat values for all parameters
rh <- mod_fit$BUGSoutput$summary[,"Rhat"]
## histogram of Rhat values for all parameters
par(mai=c(0.9,0.9,0.3,0.1))
hist(rh, breaks=seq(0.99,ceiling(max(rh)/0.01)*0.01,by=0.01),main="",
     col=rgb(0,0,255,alpha=50,maxColorValue=255),border="blue3",xlab=expression(italic(R[hat])))
## Rhat values > threshold
bad_Rhat <- rh[rh>Rhat_thresh]
## prop of params with Rhat > threshold
round(length(bad_Rhat)/length(rh),3)
## param names
par_names <- sub("\\[.*","",names(bad_Rhat))
## number of Rhat > threshold by param name
table(par_names)
## index values for offenders
idx <- as.integer(sub("(^.*\\[)([0-9]{1,3})(.*)","\\2",names(bad_Rhat)))
## data frame of offenders
(df <- data.frame(par=par_names, index=idx))
```

The convergence statistics indicate that some of the elements in $p$ for the estimated proportions of the youngest and oldest age classes (i.e., 3 and 8, respectively) did not converge to our desired threshold. However, there is very little data to inform those parameters, so we should not be too concerned.

# Main results

Here is a table of summary statistics for some of the model parameters.

```{r tbl_summary_stats}
tbl_smry <- mod_fit$BUGSoutput$summary[c("alpha","E_BH_a","beta","c1","c2"),
                                       c("mean","sd","2.5%","50%","97.5%")]
#rownames(tbl_smry)[seq(n_cov)+2] <- colnames(dat_cvrs)                                 
print(tbl_smry,digits=3,quote=FALSE,justify="right")
```

## Spawner-recruit relationship

Here is the relationship between spawner and subsequent recruits (a), assuming mean values for all covariates. Gray lines show the median relationship for each of the `r n_yrs` years based on $a_t$. Note that for plotting purposes only in (b) and (c), the density in the largest bin for each parameter contains counts for all values greater or equal to that. Vertical arrows under the x-axes in (b) and (c) indicate the 2.5^th^, 50^th^, and 97.5^th^ percentiles.

```{r plot_S_R, fig.width=8, fig.height=5, fig.pos="placeHere", eval=TRUE}
layout(matrix(c(1,1,2,3),2,2),c(3,2),c(1,1))
CI_vec <- c(0.025,0.5,0.975)
offSet <- 0.06

## posterior of spawners
sDat <- apply(mod_fit$BUGSoutput$sims.list$Sp,2,quantile,CI_vec)
sDat <- sDat[,1:(n_yrs-age_min+n_fore)]
## posterior of recruits
rDat <- exp(apply(mod_fit$BUGSoutput$sims.list$tot_ln_Rec,2,quantile,CI_vec))
## median values for a & b
aa <- apply(mod_fit$BUGSoutput$sims.list$ln_BH_a,2,median)
# bb <- apply(mod_fit$BUGSoutput$sims.list$beta,2,median)
# aa <- median(mod_fit$BUGSoutput$sims.list$alpha)
bb <- median(mod_fit$BUGSoutput$sims.list$beta)
## empty plot space for spawner-recruit relationships
dd <- 3000
yM <- Re2prec(max(rDat),"ceiling",dd)
#yM <- 30000
xM <- Re2prec(max(sDat),"ceiling",dd)
par(mai=c(0.8,0.8,0.1,0.1), omi=c(0,0,0,0))
plot(sDat[2,],rDat[2,], xlim=c(0,xM), ylim=c(0,yM), pch=16, col="blue3", type="n",
	 xaxs="i", yaxs="i", ylab="Recruits (1000s)", xlab="Spawners (1000s)", cex.lab=1.2,
	 xaxt="n", yaxt="n")
axis(1, at=seq(0,xM,dd*2), labels=seq(0,xM,dd*2)/1000)
axis(2, at=seq(0,yM,dd*2), labels=seq(0,yM,dd*2)/1000)
for(i in 1:length(aa)) { lines(exp(aa[i])*seq(0,xM)/(1+bb*seq(0,xM)), col="darkgray") }
#for(i in 1:length(aa)) { lines(aa[i]*seq(0,xM)/(1+bb*seq(0,xM)), col="darkgray") }
# lines(aa*seq(0,xM)/(1+bb*seq(0,xM)), col="darkgray")
## add S-R estimates and medians
abline(a=0,b=1,lty="dashed")
nCB <- n_yrs-age_max
points(sDat[2,1:nCB],rDat[2,1:nCB], xlim=c(0,xM), ylim=c(0,yM), pch=16, col="blue3")
segments(sDat[2,1:nCB],rDat[1,1:nCB],sDat[2,1:nCB],rDat[3,1:nCB], col="blue3")
segments(sDat[1,1:nCB],rDat[2,1:nCB],sDat[3,1:nCB],rDat[2,1:nCB], col="blue3")
nTB <- dim(sDat)[2]
clr <- rgb(100, 0, 200, alpha=seq(200,100,length.out=age_max-age_min+n_fore), maxColorValue=255)
segments(sDat[2,(nCB+1):nTB],rDat[1,(nCB+1):nTB],sDat[2,(nCB+1):nTB],rDat[3,(nCB+1):nTB], col=clr)
segments(sDat[1,(nCB+1):nTB],rDat[2,(nCB+1):nTB],sDat[3,(nCB+1):nTB],rDat[2,(nCB+1):nTB], col=clr)
points(sDat[2,(nCB+1):nTB],rDat[2,(nCB+1):nTB],
       xlim=c(0,xM), ylim=c(0,yM), pch=16, col=clr)
text(x=par()$usr[1]+par()$pin[2]/par()$pin[1]*offSet*diff(par()$usr[1:2]),
	 y=par()$usr[4]-offSet*diff(par()$usr[3:4]),"(a)")

## posterior for alpha
clr <- rgb(0, 0, 255, alpha = 50, maxColorValue = 255)
a_thresh <- 99
par(mai=c(0.8,0.4,0.3,0.1))
## B-H alpha
R_alpha_est <- mod_fit$BUGSoutput$sims.list$alpha
alphaCI <- quantile(R_alpha_est,c(0.025,0.5,0.975))
R_alpha_est[R_alpha_est>a_thresh] <- a_thresh
hist(R_alpha_est,freq=FALSE,xlab="",main="",breaks=seq(0,a_thresh+1,2),
     col=clr, border="blue3", ylab="", cex.lab=1.2, yaxt="n")
aHt <- (par()$usr[4]-par()$usr[3])/12
arrows(alphaCI,par()$usr[3],alphaCI,par()$usr[3]-aHt,
       code=1,length=0.05,xpd=NA,col="blue3",lwd=1.5)
mtext(expression(Instrinsic~productivity~(alpha)), 1, line=3, cex=1)
text(x=par()$usr[1]+par()$pin[2]/par()$pin[1]*offSet*diff(par()$usr[1:2]),
	 y=par()$usr[4]-offSet*diff(par()$usr[3:4]),"(b)")

## posterior for K
par(mai=c(0.8,0.4,0.3,0.1))
aa <- matrix(mod_fit$BUGSoutput$sims.array[,,"alpha"],ncol=1)
bb <- matrix(mod_fit$BUGSoutput$sims.array[,,"beta"],ncol=1)
R_b_est <- (aa-1)/bb
R_b_est <- R_b_est[R_b_est > 0]
R_b_CI <- quantile(R_b_est,c(0.025,0.5,0.975))
R_b_est[R_b_est>12e3] <- 12e3
brks <- seq(Re2prec(min(R_b_est),"floor",1000),
            Re2prec(max(R_b_est),"ceiling",1000),
            length.out=length(seq(0,a_thresh,2)))
hist(R_b_est, freq=FALSE, breaks=brks, col=clr, border="blue3",
	 xlab="", xaxt="n", yaxt="n",
	 main="", ylab="", cex.lab=1.2)
axis(1, at=seq(Re2prec(min(R_b_est),"floor",1000),
               Re2prec(max(R_b_est),"ceiling",1000),
               2000))
aHt <- (par()$usr[4]-par()$usr[3])/12
arrows(R_b_CI,par()$usr[3],R_b_CI,par()$usr[3]-aHt,
       code=1,length=0.05,xpd=NA,col="blue3",lwd=1.5)
mtext(expression(Carrying~capacity~(italic(K))), 1, line=3, cex=1)
text(x=par()$usr[1]+par()$pin[2]/par()$pin[1]*offSet*diff(par()$usr[1:2]),
	 y=par()$usr[4]-offSet*diff(par()$usr[3:4]),"(c)")
```

## Covariate effects

Here is the time series of the covariate and a histogram of its effects on productivity.

```{r plot_cov_effects, fig.width=8, fig.height=3, fig.pos="placeHere", warnings=FALSE, messages=FALSE}
clr <- rgb(0, 0, 255, alpha = 50, maxColorValue = 255)
par(mfrow=c(1,2), mai=c(0.7,0.2,0.1,0.1), omi=c(0,0.5,0,0))
t_idx <- seq(yr_frst,length.out=n_yrs-age_min+n_fore)
## plot covar ts
plot(t_idx, cov_flow[,best_idx+1],
     xlab="", ylab="", main="",
		 cex.axis=1, pch=16, col="blue3", type="o")
mtext(side=1,"Brood year", line=2.2)
mtext(side=2, expression(paste("Flow (",ft^3," ",s^{-1},")")), line=2.2)
## plot covar effect
c_est <- mod_fit$BUGSoutput$sims.list$c1 / sd(cov_flow[,best_idx+1])
ylN <- floor(min(c_est)*20000)/20000
ylM <- ceiling(max(c_est)*20000)/20000
brks <- seq(ylN,ylM,length.out=31)
hist(c_est,
     freq=FALSE,breaks=brks,col=clr,border="blue3",
     xlab="", yaxt="n", main="", ylab="", cex.axis=1)
c_CI <- quantile(c_est,c(0.025,0.5,0.975))
aHt <- (par()$usr[4]-par()$usr[3])/20
arrows(c_CI,par()$usr[3]-0.005,c_CI,par()$usr[3]-aHt,
       code=1,length=0.05,xpd=NA,col="blue3",lwd=1.5)
abline(v=0, lty="dashed")
mtext(side=1,"Effect size", line=2.2)
```

The median covariate effect indicates that a 1000-unit increase in flow (ft<sup>3</sup> s<sup>-1</sup>) translates into a `r round((exp(median(c_est))-1)*100*1000,1)`% change in recruits per spawner.

## Total population size

Here is our estimate of the total run size (i.e., catch + escapement) over time, which includes a forecast for 2016. The black points are the data, the blue line is the median posterior estimate, and the shaded region is the 95% credible interval. Note that the y-axis is on a log scale.

```{r plot_run_size, fig.width=6, fig.height=4.5, fig.pos="placeHere"}
pDat <- apply(mod_fit$BUGSoutput$sims.list$Sp,2,quantile,probs=CI_vec)
pDat <- pDat + matrix(dat_harv,length(CI_vec),n_yrs+n_fore,byrow=TRUE)
t_idx_f <- seq(yr_frst,length.out=n_yrs+n_fore)
ypMin <- min(pDat)
ypMax <- max(pDat)
par(mai=c(0.8,0.8,0.1,0.1), omi=c(0.5,0.2,0.1,0.2))
plot(t_idx_f,pDat[3,], ylim=c(ypMin,ypMax), type="n", log="y", xaxt="n", yaxt="n",
	 xlab="Year", ylab="Catch + escapement", main="", cex.lab=1.2)
polygon(c(t_idx_f,rev(t_idx_f)),c(pDat[3,],rev(pDat[1,])), col=clr, border=NA)
lines(t_idx_f, pDat[2,], col="blue3", lwd=2)
points(t_idx_f, exp(ln_dat_esc)+dat_harv, pch=16, cex=1)
axis(1,at=seq(1980,2015,5))
axis(2,at=c(5000,10000,20000,40000,80000))
```

Here are several percentiles for the 2016 forecast for the total run size (i.e., catch + escapement).

```{r forecast_2016}
data.frame(forecast=round(quantile(mod_fit$BUGSoutput$sims.list$Sp[,n_yrs+n_fore],
                                   probs=c(0.025,0.25,0.5,0.75,0.975))))
```

***

# Additional results

The following results are presented here as additional examples of model estimates.

## Spawners over time

Here is the estimate of the number of spawners over time. The black points are the data, the blue line is the median posterior estimate, and the shaded region is the 95% credible interval. Note that there are no estimates of spawners in 1996 & 1997.

```{r plot_spawners, fig.width=6, fig.height=4, fig.pos="placeHere"}
pDat <- apply(mod_fit$BUGSoutput$sims.list$Sp,2,quantile,CI_vec)
ypMin <- min(pDat[,1:n_yrs])
ypMax <- max(pDat[,1:n_yrs])
t_idx_T <- seq(yr_frst,length.out=n_yrs)
par(mai=c(0.8,0.8,0.1,0.1), omi=c(0,0.2,0.1,0.2))
plot(t_idx_T,pDat[3,1:n_yrs], ylim=c(ypMin,ypMax), type="n", log="y", xaxt="n", yaxt="n",
	 xlab="Year", ylab="Spawners", main="", cex.lab=1.2)
polygon(c(t_idx_T,rev(t_idx_T)),c(pDat[3,1:n_yrs],rev(pDat[1,1:n_yrs])), col=clr, border=NA)
lines(t_idx_T, pDat[2,1:n_yrs], col="blue3", lwd=2)
points(seq(yr_frst,length.out=n_yrs+n_fore), exp(ln_dat_esc), pch=16, cex=1)
axis(1,at=seq(1980,2015,5))
axis(2,at=c(4000,12000,36000))
```

## Recruits over time

Here are the estimated total number of recruits by brood year (note that the y-axis is on a log scale). Again the uncertainty increases in recent years because fewer complete age classes have been observed.

```{r plot_total_recruits, fig.width=6, fig.height=4, fig.pos="placeHere"}
CI_vec <- c(0.025,0.5,0.975)
pDat <- apply(mod_fit$BUGSoutput$sims.list$Rec,c(1,2),sum)
pDat <- apply(apply(pDat,2,sort),2,function(x) { x[mcmc_samp*CI_vec] })
ypMin <- min(pDat)
ypMax <- max(pDat)
t_idx_a <- seq(yr_frst,length.out=n_yrs-age_min+n_fore)
par(mai=c(0.8,0.8,0.1,0.1), omi=c(0,0.2,0.1,0.2))
plot(t_idx_a,pDat[3,], ylim=c(ypMin,ypMax), type="n", log="y", yaxt="n",
	 xlab="Brood year", ylab="Recruits", main="", cex.lab=1.2)
axis(2,at=c(3000,12000,48000))
polygon(c(t_idx_a,rev(t_idx_a)),c(pDat[3,],rev(pDat[1,])), col=clr, border=NA)
lines(t_idx_a, pDat[2,], col="blue3", lwd=2)
```

## Recruits per spawner

Here is the time series of estimated recruits-per-spawner. Values above (below) the dashed line at zero indicate positive (negative) population growth.

```{r plot_R_per_S, fig.width=6, fig.height=4, fig.pos="placeHere"}
pDat <- apply(mod_fit$BUGSoutput$sims.list$ln_RS,2,sort)
pDat <- apply(pDat,2,function(x) { x[mcmc_samp*CI_vec] })
pDat[2,] <- apply(mod_fit$BUGSoutput$sims.list$ln_RS,2,median)
ypMin <- min(pDat)
ypMax <- max(pDat)
par(mai=c(0.8,0.8,0.1,0.1), omi=c(0,0.2,0.1,0.2))
plot(t_idx_a,pDat[3,], ylim=c(ypMin,ypMax), type="n", #log="y",
	 xlab="Brood year", ylab="ln(R/S)", main="", cex.lab=1.2)
abline(h=0, lty="dashed")
polygon(c(t_idx_a,rev(t_idx_a)),c(pDat[3,],rev(pDat[1,])), col=clr, border=NA)
lines(t_idx_a, pDat[2,], col="blue3", lwd=2)
```

## Age composition

Here are time series of the estimated proportions of each age class by brood year (cohort).

```{r plot_age_comp, fig.width=6, fig.height=4, fig.pos="placeHere"}
par(mai=c(0.8,0.8,0.1,0.1), omi=c(0,0.1,0.2,0.2))
clr <- rgb(0, 0, 255, alpha = 40, maxColorValue = 255)
age_est <- t(apply(apply(mod_fit$BUGSoutput$sims.list$pi_vec,c(3,2),mean),2,cumsum))
nRec <- n_yrs-age_min
plot(t_idx_a, rep(1,nRec+n_fore), ylab="Proportion", xlab="Brood year", ylim=c(0,1), las=1,
     xaxs="i", yaxs="i", type="n", lty="solid", col="blue3", cex.lab=1.2)
for(i in c(1,2,3,4)) {
	polygon(c(t_idx_a,rev(t_idx_a)),c(age_est[,i],rep(0,nRec+n_fore)), col=clr, border=NA)
	}
lbl <- apply(cbind(c(0,age_est[nRec+n_fore,-A]),age_est[nRec+n_fore,]),1,mean)
text(par()$usr[2],par()$usr[4]*1.05,"Age", xpd=NA, pos=4, offset=0.05, col="black", cex=0.8)
text(par()$usr[2],lbl[1:4],seq(3,6), xpd=NA, pos=4, col="black", cex=0.7)
text(par()$usr[2],lbl[5],"7&8", xpd=NA, pos=4, offset=0.15, col="black", cex=0.7)
```

## Recruits by age class

Here are the estimated number of recruits by brood year and age. Note that the uncertainty increases in recent years as fewer complete age classes have been observed.

```{r plot_recruits_by_age, fig.width=6, fig.height=6, fig.pos="placeHere"}
CI_vec <- c(0.05,0.5,0.95)
par(mfrow=c(A,1), mai=c(0.1,0.1,0.05,0.1), omi=c(0.5,0.5,0.1,0))
t_idx_R <- seq(yr_frst,length.out=nRec+n_fore)
pltTT <- seq(min(round(t_idx_R/5,0)*5),max(round(t_idx_R/5,0)*5),5)
for(i in rev(1:A)) {
	pDat <- apply(mod_fit$BUGSoutput$sims.list$Rec[,,i],2,sort)
	pDat <- apply(pDat,2,function(x) { x[mcmc_samp*CI_vec] })/100
	dd <- ifelse(max(pDat)<20,1,10)
	ypMax <- Re2prec(max(pDat),prec=dd)
	while(ypMax %% 3 != 0) { ypMax <- ypMax + dd }
	plot(t_idx_R,pDat[3,], xlim=c(yr_frst+1,yr_last-n_fore-2), ylim=c(0.001,ypMax),
	     type="n", xaxt="n", yaxt="n", xlab="", ylab="", main="", las=1)
	polygon(c(t_idx_R,rev(t_idx_R)),c(pDat[3,],rev(pDat[1,])), col=clr, border=NA)
	lines(t_idx_R, pDat[2,], col="blue3", lwd=2)
	aHt <- (par()$usr[4]-par()$usr[3])/7
	ttl <- paste("Age-",i+age_min-1,sep="")
	text(t_idx_R[1]-0, par()$usr[4]-aHt, ttl, pos=4, cex=0.9)
	axis(2,seq(0,ypMax,length.out=4),las=1,cex=0.9)
	if(i!=1) {axis(1,at=pltTT,labels=FALSE)} else {axis(1,at=pltTT)}
}
mtext("Recruits (100s)", 2, line=2, outer=TRUE, cex=1.2)
mtext("Year", 1, line=2.5, outer=TRUE, cex=1.2)
```

## Time-varying productivity

Here is the time series of the time-varying productivity ($a_t$), which includes the cumulative effects of the `r n_mods` covariates.

```{r plot_prod_over_time, fig.width=6, fig.height=4, fig.pos="placeHere"}
pDat <- apply(mod_fit$BUGSoutput$sims.list$ln_BH_a,2,quantile,CI_vec)
ypMin <- min(pDat)
ypMax <- max(pDat)
par(mai=c(0.8,0.8,0.1,0.1), omi=c(0,0.2,0.1,0.2))
plot(t_idx_a,pDat[3,], ylim=c(ypMin,ypMax), type="n", #log="y",
	 xlab="Brood year", ylab="Productivity", main="", cex.lab=1.2)
polygon(c(t_idx_a,rev(t_idx_a)),c(pDat[3,],rev(pDat[1,])), col=clr, border=NA)
lines(t_idx_a, pDat[2,], col="blue3", lwd=2)
```

## Innovations

Here is the time series of the so-called "innovations", which are the residuals from the process model. They give some indication of population productivity after accounting for the effects of density dependence.

```{r plot_innovations, fig.width=6, fig.height=4, fig.pos="placeHere"}
pDat <- apply(mod_fit$BUGSoutput$sims.list$res_ln_Rec,2,quantile,CI_vec)
ypMin <- min(pDat)
ypMax <- max(pDat)
par(mai=c(0.8,0.8,0.1,0.1), omi=c(0,0.2,0.1,0.2))
plot(t_idx_a,pDat[3,], ylim=c(ypMin,ypMax), type="n", #log="y",
	 xlab="Brood year", ylab="Innovations", main="", cex.lab=1.2)
abline(h=0, lty="dashed")
polygon(c(t_idx_a,rev(t_idx_a)),c(pDat[3,],rev(pDat[1,])), col=clr, border=NA)
lines(t_idx_a, pDat[2,], col="blue3", lwd=2)
```

## Management reference points

Here are a number of management reference points.

```{r ref_pts}
# abbreviations for ref points
ref_names <- c("MSY","Smsy","Umsy","Umax")
# proportions of MSY to consider
yld_prop <- c(0.75,0.85,0.95)
aa <- matrix(mod_fit$BUGSoutput$sims.array[,,"E_BH_a"],ncol=1)
alpha <- matrix(mod_fit$BUGSoutput$sims.array[,,"alpha"],ncol=1)
mcmc <- length(aa)
# empty matrix for ref pts
ref.pts <- matrix(NA,mcmc,length(ref_names))
colnames(ref.pts) <- ref_names
# spawner series for optimal yield profile
SS <- seq(100,3e4,100)
# empty matrix for optimal yield profiles
OYP <- matrix(0,length(SS),length(yld_prop))
for(i in 1:mcmc) {
	# spawners at MSY
	ref.pts[i,"Smsy"] <- (1 - lambert_W0(exp(1-aa[i]))) / bb[i]
	# MSY
	ref.pts[i,"MSY"] <- ref.pts[i,"Smsy"]*((exp(aa[i]-bb[i]*ref.pts[i,"Smsy"])) - 1)
	# harvest rate at MSY
	ref.pts[i,"Umsy"] <- (1 - lambert_W0(exp(1-aa[i])))
	# max harvest rate
	ref.pts[i,"Umax"] <- 1 - 1/alpha[i]
	# yield over varying S
	yield <- SS*(exp(aa[i]-bb[i]*SS) - 1)
	for(j in 1:length(yld_prop)) {
		OYP[,j] <- OYP[,j] + 1*(yield > yld_prop[j]*ref.pts[i,"MSY"])
	}
}
OYP <- OYP/mcmc

## Prob of overfishing
hh <- seq(100)
Pr_over <- cbind(hh,hh,hh)
colnames(Pr_over) <- c("Umsy75","Umsy","Umax")
for(i in hh) {
  Pr_over[i,"Umsy75"] <- sum(ref.pts[,"Umsy"]*0.75 < i/100)/mcmc_samp
  Pr_over[i,"Umsy"] <- sum(ref.pts[,"Umsy"] < i/100)/mcmc_samp
  Pr_over[i,"Umax"] <- sum(ref.pts[,"Umax"] < i/100)/mcmc_samp
}

## posterior exploitation rate & spawner abundance
aer <- Sp_ts <- mod_fit$BUGSoutput$sims.list$Sp[,1:n_yrs]
for(i in 1:n_yrs) {
	aer[,i] <- dat_harv[i] / (dat_harv[i] + Sp_ts[,i]) 
}
```

These are plots of (a) the probability that a given number of spawners produce average yields exceeding X% of MSY (i.e, optimal yield profiles); and (b) the cumulative probabilty of overfishing the population, based on harvest rates equal to those at 75% of MSY $(U_{\text{M75}})$, MSY $(U_{\text{MSY}})$, and the maximum $(U_{\text{Max}})$. The probability of exceeding $U_{\text{Max}}$ indicates the risk that offspring will not replace their parents, which, if sustained, will lead to eventual extinction. The histograms above (a) and (b) are distributions of the posterior estimates for the number of spawners and harvest rates, respectively.

```{r plot_ref_pts, fig.width=8, fig.height=4, warning=FALSE}
layout(matrix(c(2,1,4,3),2,2),heights=c(1,5))

## OYP
par(mai=c(0.9,0.9,0,0), omi=c(0,0,0.1,0.1))
x_lp <- y_lp <- yld_prop
for(i in 1:length(x_lp)) {
	x_lp[i] <- SS[max(which(OYP[,i] == max(OYP[,i])))]
	y_lp[i] <- max(OYP[,i])
}
matplot(SS, OYP, type="l", lty="solid", las=1, col=c("slateblue","blue","darkblue"), lwd=2,
		xlab="Spawners", ylab="Probability of X% of MSY", cex.lab=1.2,
		main="", ylim=c(0,1))
points(x=x_lp, y=y_lp, pch=21, cex=3.5, col="white", bg="white")
text(x=x_lp, y=y_lp, paste0(yld_prop*100,"%"),
	 col=c("slateblue","blue","darkblue"), cex=0.7)
text(x=par()$usr[1]+par()$pin[2]/par()$pin[1]*offSet*diff(par()$usr[1:2]),
     y=par()$usr[4]-offSet*diff(par()$usr[3:4]),"(a)")
## posterior spawner abundance over all years
par(mai=c(0,0.9,0.05,0))
hist(Sp_ts[Sp_ts<3e4], col=clr, border="blue3", breaks=40,
	  main="", yaxs="i", xaxt="n",yaxt="n",ylab="")

## prob of overfishing
par(mai=c(0.9,0.9,0,0))
matplot(Pr_over, type="l", las=1, lwd=2, lty="solid", col=c("slateblue","blue","darkblue"),
        ylab="Probability of overfishing", cex.lab=1.2,
        xlab="Harvest rate", xaxt="n")
axis(1,seq(0,100,20),seq(0,100,20)/100)
x_lp <- c(0,0,0)
for(i in 1:length(x_lp)) {
	x_lp[i] <- max(which(abs(Pr_over[,i] - 0.5) <= 0.05))
}
x_lp[3] <- max(which(abs(Pr_over[,i] - 0.5) <= 0.05))
y_lp <- c(0.5,0.6,0.45)
points(x=x_lp, y=y_lp, pch=21, cex=4, col="white", bg="white")
text(x=x_lp, y=y_lp, expression(U[M75], U[MSY], U[Max]),
	 col=c("slateblue","blue","darkblue"), cex=0.8)
text(x=par()$usr[1]+par()$pin[2]/par()$pin[1]*offSet*diff(par()$usr[1:2]),
     y=par()$usr[4]-offSet*diff(par()$usr[3:4]),"(b)")
## posterior harvest rates over all years
par(mai=c(0,0.9,0.05,0))
hist(aer, col=clr, border="blue3", breaks=seq(0,40)/40,
	  main="", yaxs="i", xaxt="n",yaxt="n",ylab="")
```
